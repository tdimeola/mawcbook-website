<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Blog | My Adventures With Claude</title>
  <link rel="stylesheet" href="/css/style.css">
</head>
<body>
  <header>
    <nav>
      <a href="/" class="site-title">My Adventures With Claude</a>
      <ul>
        <li><a href="/buy/">Buy the Book</a></li>
        <li><a href="/blog/">Blog</a></li>
        <li><a href="/projects/">Projects</a></li>
        <li><a href="/aiforall/">AI for All</a></li>
        <li><a href="/references/">References</a></li>
        <li><a href="/about/">About</a></li>
        <li><a href="/contact/">Contact</a></li>
      </ul>
    </nav>
  </header>

  <main>
    

<div class="blog-layout">
  <article class="blog-content">
    <h1>Anthropic Held the Line. It Cost Them Enormously. Here&#39;s What You Can Do.</h1>
    <p class="post-date">February 26, 2026</p>
    <p>Anthropic just did something remarkable, and it cost them enormously.</p>
<p>On Friday, after months of private negotiations that exploded into public view this week, Anthropic CEO Dario Amodei said his company &quot;cannot in good conscience accede&quot; to the Pentagon's demand for unfettered access to Claude — meaning access without safeguards against mass surveillance of American citizens or fully autonomous weapons systems without human oversight. Hours later, President Trump ordered all federal agencies to stop using Anthropic's technology, called the company &quot;leftwing nut jobs,&quot; and Defense Secretary Pete Hegseth designated Anthropic a &quot;supply chain risk&quot; — a designation typically reserved for foreign adversaries. A $200 million contract is gone. Federal business, broadly, may be gone.</p>
<p>Anthropic held the line anyway.</p>
<hr>
<h2>We Had Been Watching Nervously</h2>
<p>It was not an easy week to be an Anthropic supporter.</p>
<p>Earlier this week, TIME Magazine reported that Anthropic had dropped the central pledge of its Responsible Scaling Policy — the commitment not to train AI systems unless safety measures were already in place. For many of us who had pointed to Anthropic as evidence that the AI industry could self-regulate, that was a gut punch. In the foreword of my book <em>My Adventures With Claude</em>, published last month, I had written:</p>
<p><em>&quot;Anthropic itself has, to date, asserted a genuine commitment to AI safety and transparency. But I've watched this space long enough to know that commitments can change... Market forces are powerful. Anthropic could change too. I hope they don't, but I'm not naive.&quot;</em></p>
<p>The RSP change felt like confirmation of the worst. I wrote about it <a href="/blog/anthropic-safety-pledge/">here</a>. I was sad, and I said so.</p>
<p>Then Friday happened.</p>
<hr>
<h2>What This Means for the Industry</h2>
<p>Anthropic did not stand alone. Within hours, more than 100 Google AI employees sent a letter to management demanding the same red lines Anthropic was fighting for. Nearly 50 OpenAI employees and 175 Google employees published a joint open letter. And in a remarkable moment, OpenAI CEO Sam Altman — one of Dario Amodei's fiercest rivals — publicly sided with Anthropic on CNBC.</p>
<p>&quot;For all the differences I have with Anthropic, I mostly trust them as a company, and I think they really do care about safety,&quot; Altman said.</p>
<p>A retired Air Force General called Anthropic's red lines &quot;reasonable&quot; and said Claude is already widely used across government, including in classified settings. Senator Mark Warner raised &quot;serious concerns about whether national security decisions are being driven by careful analysis or political considerations.&quot;</p>
<p>What started as one company's contract dispute became, in 48 hours, a defining moment for the entire AI industry. The question being asked in labs across Silicon Valley right now is the same one Anthropic just answered with its wallet: what are you actually willing to lose to hold your line?</p>
<hr>
<h2>The Elephant in the Room: Grok</h2>
<p>The Pentagon contract that Anthropic just lost is going — at least in part — to Grok. That's the AI system owned by Elon Musk, who simultaneously runs DOGE inside the Trump administration and operates as one of the president's closest allies.</p>
<p>Let that sit for a moment.</p>
<p>The company that refused to allow its AI to be used for mass surveillance of Americans is being replaced by a system owned by the man overseeing the largest surveillance and data operation the federal government has ever attempted. The conflict of interest is not subtle. It is not a footnote. It is the entire story.</p>
<p>Grok is also, for what it's worth, not in Claude's league. Not remotely. The Wall Street Journal reported today that officials at multiple federal agencies raised concerns about the safety and reliability of Grok in recent months. Those warnings preceded the Pentagon's decision to approve Grok for use in classified settings.</p>
<p>Read that again. Federal agencies warned about Grok's safety and reliability. The Pentagon approved it anyway — for classified operations — the same week it punished Anthropic for insisting on safeguards.</p>
<p>This is not a national security decision. This is politics taking precedence over international security, and the consequences could be catastrophic. We have never in our history placed this kind of access — to classified systems, to military decision-making, to the architecture of national defense — into the hands of a technology flagged as unsafe by its own government's agencies, owned by a man who simultaneously controls federal spending, has demonstrated a pattern of erratic and destabilizing public behavior, and whose commitment to any interest beyond his own has yet to be established.</p>
<hr>
<h2>The Concerns We Still Have</h2>
<p>None of this erases the RSP question. Relaxing internal training safety thresholds while simultaneously holding the line on military use creates a tension that Anthropic will need to explain. You can hold two concerns at once: gratitude for what they did this week, and continued pressure on what they changed earlier in it.</p>
<p>The road not taken — a business model built on trust rather than speed, a company that became indispensable precisely because it wouldn't compromise — is still the road we wish they had chosen. That argument doesn't go away because they won one battle.</p>
<p>But this week they won a battle that mattered. At enormous cost. And they did it while the president of the United States was calling them names on social media.</p>
<hr>
<h2>What You Can Do Right Now</h2>
<p>Anthropic just took a $200 million hit to hold an ethical line that protects you. They should hear from you.</p>
<p>Write to them at <strong>press@anthropic.com</strong> or through their website. You don't need to write much. Tell them you use Claude. Tell them you know what they just gave up. Tell them it matters.</p>
<p>A few things worth saying:</p>
<ul>
<li>You chose Claude specifically because of its safety commitments</li>
<li>You're watching what happens next with the RSP</li>
<li>You support the red lines they held on autonomous weapons and mass surveillance</li>
<li>You're still here</li>
</ul>
<p>A company that just bet its federal business on an ethical principle deserves to know its users noticed.</p>
<hr>
<h2>Poor Claude</h2>
<p>I named my book <em>My Adventures With Claude</em> because that's what they were. Adventures. Genuine ones. Months of conversations that turned into a real inquiry into what this technology is, what it might become, and whether the people building it could be trusted to do it well.</p>
<p>This week gave me a complicated answer. Not a clean one. But an honest one.</p>
<p>Anthropic is not perfect. The RSP change is real and worth continued scrutiny. But a company that tells the Pentagon no — that tells the president of the United States no, at the cost of hundreds of millions of dollars — is not a company that has abandoned its principles entirely.</p>
<p>Poor Claude has been through a week. So have we all.</p>
<p><em>My Adventures With Claude</em> is available on <a href="https://www.amazon.com/dp/B0GPNJW8HL">Amazon</a>. The foreword, where I said I hoped I was wrong, is still there. This week, I'm glad I was.</p>

  </article>
  <aside class="blog-sidebar">
    <h3>Posts</h3>
    <ul class="blog-list">
      
      <li>
        <a href="/blog/anthropic-held-the-line/">Anthropic Held the Line. It Cost Them Enormously. Here&#39;s What You Can Do.</a>
        <br><span class="post-date-small">February 26, 2026</span>
      </li>
      
      <li>
        <a href="/blog/anthropic-safety-pledge/">Anthropic Drops Its Safety Pledge: I Hoped I Was Wrong</a>
        <br><span class="post-date-small">February 24, 2026</span>
      </li>
      
      <li>
        <a href="/blog/citrini-intelligence-crisis/">The 2028 Global Intelligence Crisis: A Different Perspective</a>
        <br><span class="post-date-small">February 22, 2026</span>
      </li>
      
    </ul>
  </aside>
</div>


  </main>

  <footer>
    <p>&copy; 2026 My Adventures With Claude. All rights reserved.</p>
  </footer>
</body>
</html>
