# The 2028 Global Intelligence Crisis: A Different Perspective

*Draft blog post - based on conversation 2026-02-23. Finish and post when website goes live.*

---

## Source

"The 2028 Global Intelligence Crisis: A Thought Exercise in Financial History, from the Future"
Citrini Research / Alap Shah, February 22, 2026
https://alapshah1.substack.com/p/the-global-intelligence-crisis


---

## The Irony Note (open with this)

*A brief note: I wrote this as a comment on the original piece, then discovered that commenting requires a $125/month subscription. The irony of that particular friction tax was too good not to mention.*

I first discovered this post on the Wall Street Journal, but within a day all the major news outlets (and some I do not peruse) and picked up on it calling it a "doomsday scenario" - which it kind of is. So for those who picked up on that bravo. But for the many that just gulped and moved on, well, DON'T DO THAT!

Here is the comment that I was originally going to post, but didn't due to the paywall noted above, and below it my further thoughts.

---

## The Comment

Fascinating piece, and one of the more honest attempts I've seen to model left-tail AI risk without sliding into doomerism or denial. A few thoughts from someone who has spent the last year studying AI closely enough to write a book about it for general audiences.

The timeline is doing a lot of heavy lifting, and I think it's probably too compressed by a factor of three to five. Not because the mechanisms are wrong - they're mostly right - but because organizational inertia is real. Enterprise software contracts have multi-year lock-ins. Procurement committees are slow. Regulatory friction exists. The 2026-to-2028 cascade assumes near-perfect propagation speed across an economy that moves in half-decades, not quarters. The dynamics are sound; the clock is probably off.

On the core analysis: agreed. The Ghost GDP concept is useful and underappreciated. The reflexivity point - that threatened companies become AI's most aggressive adopters - is sharp and underexplored elsewhere. And the white-collar concentration risk is genuinely different from prior recessions in ways most frameworks aren't equipped for.

Here's what I'd add, as a different perspective rather than a correction: this piece is written from the viewpoint of people who built and invested in the intermediation layer. That's a legitimate vantage point. But it's worth sitting with the fact that many of the business models it mourns weren't serving ordinary people particularly well. Insurance companies profiting from policyholder inertia. Platform rake. Subscription lock-in engineered around consumer helplessness. SaaS pricing built on switching costs. These weren't neutral features of commerce - they were deliberately constructed to extract value from people who lacked time, information, or leverage.

The crisis the piece describes is real for certain stakeholders. It reads quite differently if you're not one of them.

This isn't everyone's threat model. Many people - probably more than the piece assumes - would trade the current arrangement for a shorter workweek, a care economy, and a fairer distribution of productivity gains. The Shared AI Prosperity Act gets one paragraph and then the piece moves on. That's where the more interesting conversation lives.

The policy question - who captures the gains from abundant intelligence - matters more than whether SaaS multiples stabilize. The canary is still alive, as you say. But not everyone in the mine is rooting for the same outcome.

## What I REALLY Feel
The piece is a crisis narrative for capital, not for people. Every business model it mourns was a mechanism for extracting value from people who lacked time, information, or leverage:
- Insurance inertia (15-20% of premiums from passive renewals)
- DoorDash rake (30% of delivery fees)
- SaaS lock-in ($500k/year renewals people couldn't escape)
- Real estate commissions (5-6% built on information asymmetry)
- Credit card interchange (2-3% on every transaction)
- Subscription dark patterns (pricing that doubled after trials)

The "friction" AI is eliminating wasn't natural. It was engineered and defended deliberately.

### What jobs remain
Roughly: whatever requires physical presence in unstructured environments (trades, construction, emergency services), genuine human relationship as the product itself (therapy, care work, teaching), embodied judgment in chaotic situations (nurses, paramedics, social workers), local trust and accountability, democratic and community governance, live performance and presence.

Notice: almost entirely work that has been *undervalued and underpaid* precisely because it doesn't scale and can't be intermediated efficiently.

### The policy question (where the real story is)
- UBI funded by productivity gains / AI inference tax
- Public ownership stake in AI infrastructure (the Shared AI Prosperity Act the piece breezes past)
- Shorter work weeks
- Expansion of care economy as real, compensated work
- Universal healthcare decoupled from employment
- Local, circular economies

The transition pain is real even if the destination is fairer. That's worth acknowledging.

---

*Post to mawcbook.com/blog when site is live.*
